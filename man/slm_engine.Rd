% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/slm_engine.R
\name{slm_engine}
\alias{slm_engine}
\title{Native SLM (Small Language Model) Engine}
\usage{
slm_engine(model_path, backend = "gguf", config = list())
}
\arguments{
\item{model_path}{Path to the model weights file.}

\item{backend}{Inference backend: "gguf" (default), "onnx", or "torch".}

\item{config}{Optional configuration list.}
}
\value{
An SlmEngine object.
}
\description{
Generic interface for loading and running local language models without
external API dependencies. Supports multiple backends including ONNX Runtime
and LibTorch for quantized model execution.

Factory function to create a new SLM Engine for local model inference.
}
\examples{
\dontrun{
# Load a GGUF model
engine <- slm_engine("models/llama-3-8b-q4.gguf")
engine$load()

# Generate text
result <- engine$generate("What is the capital of France?")
cat(result$text)

# Stream generation
engine$stream("Tell me a story", callback = cat)

# Cleanup
engine$unload()
}
}
