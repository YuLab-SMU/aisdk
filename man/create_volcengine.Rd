% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/provider_openai.R
\name{create_volcengine}
\alias{create_volcengine}
\title{Create Volcengine/Ark Provider}
\usage{
create_volcengine(api_key = NULL, base_url = NULL, headers = NULL)
}
\arguments{
\item{api_key}{Volcengine API key. Defaults to ARK_API_KEY env var.}

\item{base_url}{Base URL for API calls. Defaults to https://ark.cn-beijing.volces.com/api/v3.}

\item{headers}{Optional additional headers.}
}
\value{
An OpenAIProvider object configured for Volcengine.
}
\description{
Convenience function to create a Volcengine (火山引擎) provider using the Ark API.
This is a wrapper around create_openai with Volcengine-specific defaults.
}
\section{Token Limit Parameters for Volcengine Responses API}{

Volcengine's Responses API has two mutually exclusive token limit parameters:

\itemize{
\item \code{max_output_tokens}: Total limit including reasoning + answer (default mapping)
\item \code{max_tokens} (API level): Answer-only limit, excluding reasoning
}

The SDK's unified \code{max_tokens} parameter maps to \code{max_output_tokens} by default,
which is the \strong{safe choice} to prevent runaway reasoning costs.

For advanced users who want answer-only limits:
\itemize{
\item Use \code{max_answer_tokens} parameter to explicitly set answer-only limit
\item Use \code{max_output_tokens} parameter to explicitly set total limit
}
}

\examples{
\dontrun{
volcengine <- create_volcengine()

# Chat API (standard models)
model <- volcengine$language_model("doubao-1-5-pro-256k-250115")
result <- generate_text(model, "你好")

# Responses API (reasoning models like DeepSeek)
model <- volcengine$responses_model("deepseek-r1-250120")

# Default: max_tokens limits total output (reasoning + answer)
result <- model$generate(messages = msgs, max_tokens = 2000)

# Advanced: limit only the answer part (reasoning can be longer)
result <- model$generate(messages = msgs, max_answer_tokens = 500)

# Advanced: explicitly set total limit
result <- model$generate(messages = msgs, max_output_tokens = 3000)
}
}
