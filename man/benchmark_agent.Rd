% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/agent_evals.R
\name{benchmark_agent}
\alias{benchmark_agent}
\title{Benchmark Agent}
\usage{
benchmark_agent(agent, tasks, tools = NULL, verbose = TRUE)
}
\arguments{
\item{agent}{An Agent object or model string.}

\item{tasks}{A list of benchmark tasks (see details).}

\item{tools}{Optional list of tools for the agent.}

\item{verbose}{Print progress.}
}
\value{
A benchmark result object with metrics.
}
\description{
Run a benchmark suite against an agent and collect performance metrics.
}
\details{
Each task in the tasks list should have:
\itemize{
\item prompt: The task prompt
\item expected: Expected output or criteria
\item category: Optional category for grouping
\item ground_truth: Optional ground truth for hallucination checking
}
}
